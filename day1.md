[TOC]


## 【任务1 - 线性回归算法梳理】时长：2天
机器学习的一些概念
1. 有监督、无监督、泛化能力、过拟合欠拟合(方差和偏差以及各自解决办法)、交叉验证
2. 线性回归的原理
3. 线性回归损失函数、代价函数、目标函数
4. 优化方法(梯度下降法、牛顿法、拟牛顿法等)
5. 线性回归的评估指标
6. sklearn参数详解

### 有监督、无监督、泛化能力、过拟合欠拟合(方差和偏差以及各自解决办法)、交叉验证
- 监督学习，无监督学习
#### 监督学习
机器学习如何解决分类问题, 它的主要任务是将实例数据划分到合适的分类中。机器学习的另一项任务是回归,它主要用于预测数值型数据。大多数人可能都见过回归的例子——数据拟合曲线:通过给定数据点的最优拟合曲线。分类和回归属于监督学习,之所以称之为监督学习,是因为这类算法必须知道预测什么,即目标变量的分类信息。 
监督学习的常用算法：

|  |  |
| --- | --- |
| K近邻算法 | 线性回归 |
| 朴素贝叶斯算法 | 局部加权线性回归 |
| 支持向量机 | Ridge回归 |
| 决策树 | Lasso最小回归系数估计 |



#### 无监督学习
无监督学习,此时数据没有类别信息,也不会给定目标值。在无监督学习中, 将数据集合分成由类似的对象组成的多个类的过程被称为聚类; 将寻找描述数据统计值的过程称之为密度估计。此外,无监督学习还可以减少数据特征的维度,以便我们可以使用二维或三维图形更加直观地展示数据信息。

|  |  |
| --- | --- |
|K-均值  | 最大期望算法  |
| DBSCAN | Parzen窗设计 |


#### 二者不同点
1. 有监督学习方法必须要有训练集与测试样本。在训练集中找规律，而对测试样本使用这种规律。而非监督学习没有训练集，只有一组数据，在该组数据集内寻找规律。

2.    有监督学习的方法就是识别事物，识别的结果表现在给待识别数据加上了标签。因此训练样本集必须由带标签的样本组成。而非监督学习方法只有要分析的数据集的本身，预先没有什么标签。如果发现数据集呈现某种聚集性，则可按自然的聚集性分类，但不予以某种预先分类标签对上号为目的。

3. 非监督学习方法在寻找数据集中的规律性，这种规律性并不一定要达到划分数据集的目的，也就是说不一定要“分类”。
这一点是比有监督学习方法的用途要广。    譬如分析一堆数据的主分量，或分析数据集有什么特点都可以归于非监督学习方法的范畴。

4. 用非监督学习方法分析数据集的主分量与用K-L变换计算数据集的主分量又有区别。后者从方法上讲不是学习方法。因此用K-L变换找主分量不属于无监督学习方法，即方法上不是。而通过学习逐渐找到规律性这体现了学习方法这一点。在人工神经元网络中寻找主分量的方法属于无监督学习方法。 

#### 何时采用哪种方法
简单的方法就是从定义入手，有训练样本则考虑采用监督学习方法；无训练样本，则一定不能用监督学习方法。但是，现实问题中，即使没有训练样本，我们也能够凭借自己的双眼，从待分类的数据中，人工标注一些样本，并把它们作为训练样本，这样的话，可以把条件改善，用监督学习方法来做。对于不同的场景，正负样本的分布如果会存在偏移（可能大的偏移，可能比较小），这样的话，监督学习的效果可能就不如用非监督学习了

#### 泛化能力
学习方法的泛化能力(generalization ability)是指由该方法学习到的模型对未知数据的预测能力,是学习方法本质上重要的性质。现实中采用最多的办法是通过测试误差来评价学习方法的泛化能力。但这种评价是依赖于测试数据集的。因为测试数据集是有限的, 很有可能由此得到的评价结果是不可靠的。统计学习理论试图从理论上对学习方法的泛化能力进行分析。

泛化能力：是指一个模型应用到新样本的能力。这里的新样本是指没有出现在训练集中的数据。


过拟合欠拟合(方差和偏差以及各自解决办法)、交叉验证
线性回归的原理
线性回归损失函数、代价函数、目标函数
优化方法(梯度下降法、牛顿法、拟牛顿法等)
线性回归的评估指标
sklearn参数详解

过拟合欠拟合(方差和偏差以及各自解决办法)、交叉验证
1.过拟合：就是训练时的结果很好，但是在预测时结果不好的情况。

2.产生过拟合的原因：

（1)   模型的复杂度太高。比如：网络太深，

（2）过多的变量（特征）

（3）训练数据非常少。

3.如何解决过拟合？

避免过拟合的方法有很多：
（1）尽量减少特征的数量、
（2）early stopping、
（3）数据集扩增、
（4）dropout、
（5）正则化包括L1、L2、
（6）清洗数据

什么是欠拟合+为什么会产生欠拟合？（高偏差）+怎么解决欠拟合？

1.什么是欠拟合？

      模型没有很好地捕捉到数据特征，不能够很好地拟合数据的情况，就是欠拟合。

2.为什么会产生欠拟合？

因为模型不够复杂而无法捕捉数据基本关系，导致模型错误的表示数据。
比如：（1）如果对像是按照颜色和形状进行分类的，但是模型只能按照颜色来区分对象和将对象分类，因而一直会错误的分类对象。（2）我们的模型可能是多项式的形式，但是训练出来的模型却只能表示线性关系。

3.怎么解决欠拟合？

1）添加其他特征项，有时候我们模型出现欠拟合的时候是因为特征项不够导致的，可以添加其他特征项来很好地解决。例如，“组合”、“泛化”、“相关性”三类特征是特征添加的重要手段，无论在什么场景，都可以照葫芦画瓢，总会得到意想不到的效果。除上面的特征之外，“上下文特征”、“平台特征”等等，都可以作为特征添加的首选项。

2）添加多项式特征，这个在机器学习算法里面用的很普遍，例如将线性模型通过添加二次项或者三次项使模型泛化能力更强。例如上面的图片的例子。

3）减少正则化参数，正则化的目的是用来防止过拟合的，但是现在模型出现了欠拟合，则需要减少正则化参数。

避免欠拟合(刻画不够)
寻找更好的特征—–具有代表性的
用更多的特征—–增大输入向量的维度

方差、偏差的应用场景？
用于计算模型的好坏。具体是使用error公式。
Error = Bias^2 + Variance+Noise
什么是Bias(偏差)：Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度，即算法本身的拟合能力
什么是Variance(方差)：Variance反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性。反应预测的波动情况。
什么是Noise(噪声)：这就简单了，就不是你想要的真正数据，你可以想象为来破坏你实验的元凶和造成你可能过拟合的原因之一，至于为什么是过拟合的原因，因为模型过度追求Low Bias会导致训练过度，对测试集判断表现优秀，导致噪声点也被拟合进去了


三、什么是方差？

1.方差的定义：

什么是Variance(方差)：Variance反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性。反应预测的波动情况。

2.方差和偏差的形象化表示？靶心和射击的结果。

https://img-blog.csdn.net/20180406141219967?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTIxOTc3NDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70

其中，bias表示的是偏差，描述的是模型和预测结果和真实结果的差距;variance表示的是方差。

图中的靶心就是我们的真实值。

离靶心的距离反映了我们的偏差有多大。离靶心越近，偏差越小;离靶心越远，方差越大。

点的聚集程度反映了我们的方差有多大。越分散，方差越大。越聚拢，方差越小。

举个例子来理解：两个射击选手在射靶。甲射出的子弹很集中在某个区域，但是都偏离了靶心。我们说他的射击很稳定，但是不够准，准确性差。也就是说他的方差小（子弹很集中在某个区域），但是他的偏差大（子弹打中的地方距离靶心远）。相反，乙射出的子弹比较分散，但是有些很准，中了靶心。我们说他射击比较准，但是发挥不够稳定，稳定性差。 

所以，偏差是描述了准确性。方差是描述稳定性。

四、什么是偏差？

1.偏差的定义：

什么是Bias(偏差)：Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度，即算法本身的拟合能力


方差、偏差和过拟合、欠拟合之间的关系?偏差、方差与欠拟合、过拟合之间又有什么关系呢？
过拟合会出现高方差问题
欠拟合会出现高偏差问题

https://img-blog.csdn.net/20170807200653074?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGl3ZWliaW4xOTk0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast
